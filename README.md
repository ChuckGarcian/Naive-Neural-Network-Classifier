# Naive-Neural-Network

This project provides a basic implementation of a neural network using stochastic gradient descent. It includes ReLU, Leaky ReLU, and Sigmoid activation functions, and supports Mean Squared Error (MSE) and Mean Absolute Error (MAE) for loss calculation. The network is tested on tasks like summing digits, multiplying digits, and classifying handwritten digits. Digit classification can be attained with 90% accuracy.
